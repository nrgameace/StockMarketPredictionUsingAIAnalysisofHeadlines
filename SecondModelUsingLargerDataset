{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0nnOCTrtDmMaumK5NfuQR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Brj7KYOsK8U4"},"outputs":[],"source":["#Import all the necessary libraries needed\n","import pandas as pd\n","import os\n","import torch\n","from transformers import BertTokenizer, BertModel\n","import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","import pickle\n","from tqdm import tqdm\n","from torch.cuda.amp import autocast\n","import logging\n","import psutil\n","import math\n","import sys\n","import uuid\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import torch.optim as optim\n","import ast\n","\n","print(\"All is good\")"]},{"cell_type":"code","source":["#Import the two datasets from a local file into Python\n","dfNews = pd.read_csv('/home/nickregas/Desktop/IndependentCompsciProject/Data/All_external.csv')\n","dfStock = pd.read_csv('/home/nickregas/Desktop/IndependentCompsciProject/Data/VTI.csv')"],"metadata":{"id":"gvRY1udBLH4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cleaning the dataset\n","\n","#Creates a new column called Increase that sets itself as true if the difference of the close price and open price is positive and false if negative\n","dfStock['Increase'] = (dfStock['close'] - dfStock['open']) > 0\n","\n","#Gets rid of the following columns in the stock dataset\n","dfStock = dfStock.drop(['open', 'close', 'volume', 'high', 'low', 'adj close'], axis=1)\n","\n","#Gets rid of the following columns in the news dataset\n","dfNews = dfNews.drop(['Stock_symbol', 'Url', 'Publisher', 'Author', 'Article', 'Lsa_summary', 'Luhn_summary', 'Textrank_summary', 'Lexrank_summary'], axis=1)\n","\n","#This line gets rid of the timestamp for each article and only keeps the date it was published\n","dfNews['Date'] = dfNews['Date'].str.split(' ').str[0]\n","\n","#Renames a column in the dfNews dataset\n","dfNews = dfNews.rename(columns={'Date': 'date'})\n","\n","dfNews.head()\n","dfStock.head()"],"metadata":{"id":"s3Or2t4SLQ9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#This merges the two separate datasets into one by matching the dates in each dataset and combining their other columsn together\n","merged_df = pd.merge(dfNews[['date', 'Article_title']], dfStock[['date', 'Increase']], on='date', how='inner')"],"metadata":{"id":"0xEH9GvTL_Qx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Attempts to use graphics card for faster processing and defaults back to cpu if not avaliable\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device: \" + str(device))\n","\n","# Instantiating the Bert tokenizer and model which converts the tokens to vectors\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n","model.eval()\n","\n","# Function to convert article title to vector\n","def title_to_vector(title):\n","    # Tokenize the title\n","    inputs = tokenizer(title, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n","\n","    # Move inputs to GPU\n","    inputs = {key: val.to(device) for key, val in inputs.items()}\n","\n","    # Get BERT embeddings\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        # Use [CLS] token embedding (first token)\n","        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","\n","    return embedding.flatten()\n","\n","\n","#Creates a new column for the vector\n","vectors = []\n","\n","#Creates a progress bar to view percentage live\n","for title in tqdm(merged_df[\"Article_title\"], desc=\"Converting titles to vectors\"):\n","    # Check if title is a valid string and not NaN\n","    if isinstance(title, str) and pd.notna(title):\n","        vector = title_to_vector(title)\n","        vectors.append(vector)\n","    else:\n","        vectors.append(\"N/A\")  # Append placeholder for invalid inputs\n","\n","#Adds the completed vectors to dataframe\n","merged_df[\"Title_vector\"] = vectors\n","\n","#Sets the file path where the new dataset will be saved\n","outputDirectory = \"/home/nickregas/Desktop/IndependentCompsciProject/Data\"\n","os.makedirs(outputDirectory, exist_ok=True)  # Create directory if it doesn't exist\n","outputFilename = os.path.join(outputDirectory, \"DatasetWithVectors.csv\")\n","\n","#Save the dataset localy\n","merged_df.to_csv(outputFilename, index=False)\n","print(\"Dataset saved as output_filename\" + outputFilename)"],"metadata":{"id":"cyuHtxW8MKaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Checks to ensure that model is using my graphics card\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device: \" + str(device))\n","\n","#This class helps convert the data in the dataset into data that the torch dataloader can feed the model during training\n","class StockDataset(Dataset):\n","    #Converts vectors to tensors once at init to pass into graphics card\n","    def __init__(self, vectors, labels):\n","        self.X = torch.tensor(vectors, dtype=torch.float32).to(device)\n","        self.y = torch.tensor(labels, dtype=torch.float32).to(device)\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# This is the actual model which is a subclass of nn.Module\n","class StockPredictor(nn.Module):\n","    # Simple feedforward net with dropout.\n","    def __init__(self, input_dim=768):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x).squeeze(-1)  # Avoid explicit squeeze() later\n","\n","def parse_vector(raw):\n","    # Checks if vector is not the right format\n","    if pd.isna(raw) or not raw or raw == \"N/A\":\n","        return None\n","    try:\n","        return np.array(ast.literal_eval(raw), dtype=np.float32)\n","    except (ValueError, SyntaxError):\n","        return None\n","\n","# Loads the dataset\n","DATA_PATH = \"/home/nickregas/Desktop/IndependentCompsciProject/Data/merged_df_with_vectors_91c6e7ea45e74694b177f97b932cd48c.csv\"\n","if not os.path.exists(DATA_PATH):\n","    raise FileNotFoundError(\"Data file not found at \" + DATA_PATH)\n","\n","print(\"Loading and filtering data...\")\n","df = pd.read_csv(DATA_PATH, usecols=[\"Title_vector\", \"Increase\"])\n","parsed_vectors = df[\"Title_vector\"].apply(parse_vector)\n","valid_mask = parsed_vectors.notna()\n","\n","vectors = np.stack(parsed_vectors[valid_mask].values)\n","labels = df[\"Increase\"].values[valid_mask]\n","\n","# Create the training data\n","X_train, X_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.2, random_state=42)\n","train_loader = DataLoader(StockDataset(X_train, y_train), batch_size=64, shuffle=True)\n","test_loader = DataLoader(StockDataset(X_test, y_test), batch_size=64)\n","\n","model = StockPredictor().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","loss_fn = nn.BCELoss()\n","\n","# Loop for training\n","print(\"Training...\")\n","for epoch in range(1, 11):\n","    model.train()\n","    epoch_loss = 0.0\n","\n","    for X_batch, y_batch in tqdm(train_loader, desc=\"Epoch \" + str(epoch) + \"/10\"):\n","        optimizer.zero_grad()\n","        loss = loss_fn(model(X_batch), y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    print(\"Epoch \" + str(epoch) + \" | Avg Loss: \" + str(round(epoch_loss / len(train_loader), 4)))\n","\n","# Code for evaluation\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for X_batch, y_batch in test_loader:\n","        preds = (model(X_batch) >= 0.5).float()\n","        correct += (preds == y_batch).sum().item()\n","        total += len(y_batch)\n","\n","accuracy = correct / total * 100\n","print(\"Test Accuracy: \" + str(round(accuracy, 2)) + \"%\")\n","\n","# Save model\n","MODEL_PATH = \"/home/nickregas/Desktop/IndependentCompsciProject/Data/stock_predictor_model.pth\"\n","os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n","torch.save(model.state_dict(), MODEL_PATH)\n","print(\"Model saved to \" + MODEL_PATH)"],"metadata":{"id":"Sz03yIExNlx_"},"execution_count":null,"outputs":[]}]}